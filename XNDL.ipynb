{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import de la base de dades i de les llibreries a utilitzar\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llibreries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dades\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smartphone_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÀLISIS I PREPROCESSAT DE DADES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fast_charging_available'] = df['fast_charging_available'].astype(bool)\n",
    "df['extended_memory_available'] = df['extended_memory_available'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per molt que `fast_charging` sembli una numèrica, realment és una categòrica ja que expressa el tipus de càrrega ràpida. Passa també amb moltes altres variables, com podrien ser `battery_size`, `num_cores`, `ram_capacity` o `screen_size`. Així doncs, tot i que aquestes variables haurien de ser tractades com a categòriques, ja que estan representades com a numèriques, les tractarem com a numèriques per a que el model predictiu pugui ser més precís i obtenir millors resultats, ja que el model que utilitzarem treballa millor amb variables numèriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('model', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminem la variable ´model´ ja que no aporta cap informació rellevant per a la predicció."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi univariant de les dades\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de variables categoricas y booleanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analisis_estadistic_cat_bool(df):\n",
    "    for feature in df.columns:\n",
    "        if df[feature].dtype == 'object' or df[feature].dtype == 'bool':\n",
    "            # Calculamos el conteo y el porcentaje para cada categoría\n",
    "            df_count = df[feature].value_counts().reset_index()\n",
    "            df_count.columns = [feature, 'count']\n",
    "            df_count['percent'] = 100 * df_count['count'] / df_count['count'].sum()\n",
    "\n",
    "            # Creamos la gráfica de barras con colores distintos para cada categoría\n",
    "            fig = px.bar(df_count, x=feature, y='count', text='percent', color=feature)\n",
    "\n",
    "            # Actualizamos el layout para añadir título y etiquetas\n",
    "            fig.update_layout(\n",
    "                title=f'Distribución de la variable {feature}',\n",
    "                xaxis_title=feature,\n",
    "                yaxis_title='Conteo'\n",
    "            )\n",
    "\n",
    "            # Añadir el porcentaje en las barras\n",
    "            fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_estadistic_cat_bool(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chat.openai.com/share/06002044-fa85-4c48-927b-a35ceb5b3d0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver datos únicos para identificar formatos incorrectos\n",
    "df['fast_charging'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asumim que 6n7.0 es un error tipografic i que realment volien dir 67.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['fast_charging'] = df['fast_charging'].replace('6n7.0', '67.0')\n",
    "\n",
    "df['fast_charging'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fast_charging'] = df['fast_charging'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processor_brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos los valores 'sc9863a' por 'spreadtrum' en la columna 'processor_brand'\n",
    "df['processor_brand'] = df['processor_brand'].replace('sc9863a', 'spreadtrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis variables numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos solo las columnas numéricas\n",
    "numerical_columns = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Generamos la tabla de estadísticas descriptivas\n",
    "statistics_table = numerical_columns.describe()\n",
    "\n",
    "# Imprimimos la tabla\n",
    "statistics_table.describe().round(2).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_estadistic_num(df, numerical_columns):\n",
    "    for feature in numerical_columns:\n",
    "        # Histograma\n",
    "        fig = px.histogram(df, x=feature, marginal=\"box\",\n",
    "                        title=f'Histograma de {feature}')\n",
    "        fig.update_layout(xaxis_title=feature, yaxis_title='Conteo')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_estadistic_num(df, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chat.openai.com/share/06002044-fa85-4c48-927b-a35ceb5b3d0a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi multivariant\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"holaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudi de balanceig de classes (documento)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degut a que el objectiu es fer una regresio per predir el preu no fa falta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numerical_columns:\n",
    "    # Calculem el nombre de valors absents\n",
    "    missing_count = df[feature].isnull().sum()\n",
    "    # Calculem el percentatge de valors absents\n",
    "    missing_percentage = (missing_count / len(df)) * 100\n",
    "\n",
    "    if missing_count > 0:\n",
    "        print(f\"La variable {feature} té {missing_count} valors absents, el que representa un {missing_percentage:.2f}%.\")\n",
    "    else:\n",
    "        print(f\"La variable {feature} no té valors absents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de imputar tendremos que convertir a categoricas las variables que son categoricas pero estan representadas como numericas para evitar que se imputen valores incorrectos en las variables. Luego las volveremos a convertir a numericas para que el modelo las trate como tal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFORME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature creation \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chat.openai.com/share/06002044-fa85-4c48-927b-a35ceb5b3d0a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Variables Numéricas Separadas para Ancho y Alto:\n",
    "*Proceso: Puedes separar la resolución indicada como \"1080x2400\" en dos variables numéricas distintas: una para el ancho (1080) y otra para el alto (2400). Esto te permite conservar la información sobre la dimensión de la pantalla de manera más específica y útil para el modelo.\n",
    "*Ventajas: Al mantener estas dimensiones como numéricas, tu modelo puede aprender cómo diferentes resoluciones, ya sea más anchas o más altas, afectan al precio. Además, al separarlas, permites que el modelo ajuste independientemente el impacto del ancho y del alto.\n",
    "\n",
    "\n",
    "separar las dimensiones permite al modelo aprender diferencias específicas en cómo el ancho y el alto afectan al precio, lo cual puede ser más informativo dado que ciertas proporciones de pantalla son más deseables en ciertos mercados o tendencias de diseño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas columnas 'width' y 'height'\n",
    "df[['width', 'height']] = df['resolution'].str.split('x', expand=True).astype(int)\n",
    "\n",
    "df.drop('resolution', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extend memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partició de les dades\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = shuffle(df, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partició"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(df_shuffled, test_size=0.30, random_state=69)\n",
    "test, val = train_test_split(test, test_size=0.50, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tractament de missings\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertim a categoriques les variables que haurien de ser-ho per a la imputació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoimputem missings a la db per veure els millors models per imputar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funció per crear missings de manera controlada\n",
    "def autoimpute_missing_values(data, missing_rate=0.1):\n",
    "    df_missing = data.copy()\n",
    "    for col in df_missing.columns:\n",
    "        missing_indices = np.random.choice(df_missing.index, int(\n",
    "            len(df_missing) * missing_rate), replace=False)\n",
    "        # Reemplazar 'nan' con np.nan\n",
    "        df_missing.loc[missing_indices, col] = np.where(\n",
    "            df_missing.loc[missing_indices, col] == 'nan', np.nan, df_missing.loc[missing_indices, col])\n",
    "    return df_missing\n",
    "\n",
    "# Autoimputem missings\n",
    "df_missing = autoimpute_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertim tots els nan a np.nan\n",
    "df_missing = df_missing.replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionem només les columnes numèriques\n",
    "numeric_cols = df_missing.select_dtypes(include=[np.number]).columns\n",
    "df_missing_numeric = df_missing[numeric_cols]\n",
    "\n",
    "# Funció per imputar valors numèrics amb RandomForest o HistGradientBoosting\n",
    "def impute_numeric(data, cols, model_type='random_forest'):\n",
    "    imputed_data = data.copy()\n",
    "    for col in cols:\n",
    "        # Comprova si hi ha files per imputar\n",
    "        if imputed_data[col].isnull().sum() > 0:\n",
    "            # Preparació del conjunt de dades\n",
    "            train = imputed_data[imputed_data[col].notnull()]\n",
    "            test = imputed_data[imputed_data[col].isnull()]\n",
    "            y_train = train[col]\n",
    "            X_train = train.drop(col, axis=1)\n",
    "            X_test = test.drop(col, axis=1)\n",
    "\n",
    "            # Omplir valors NaNs en X_train i X_test\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            X_train_imputed = imputer.fit_transform(X_train)\n",
    "            X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "            # Imputació amb el model seleccionat\n",
    "            if model_type == 'random_forest':\n",
    "                model = RandomForestRegressor(n_estimators=100)\n",
    "            else:  # HistGradientBoosting\n",
    "                model = HistGradientBoostingRegressor()\n",
    "\n",
    "            model.fit(X_train_imputed, y_train)\n",
    "            imputed_values = model.predict(X_test_imputed)\n",
    "\n",
    "            # Assignació dels valors imputats\n",
    "            imputed_data.loc[imputed_data[col].isnull(), col] = imputed_values\n",
    "\n",
    "\n",
    "    return imputed_data\n",
    "\n",
    "\n",
    "\n",
    "# Imputació amb RandomForest o HistGradientBoosting\n",
    "df_numeric_rf = impute_numeric(df_missing_numeric, numeric_cols, model_type='random_forest')\n",
    "df_numeric_hgb = impute_numeric(df_missing_numeric, numeric_cols, model_type='hist_gradient_boosting')\n",
    "\n",
    "# Imputació amb MICE\n",
    "mice_imputer = IterativeImputer()\n",
    "df_numeric_mice = df_missing_numeric.copy()\n",
    "imputed_data = mice_imputer.fit_transform(df_missing_numeric)\n",
    "\n",
    "df_numeric_mice_imputed = pd.DataFrame(imputed_data, columns=df_missing_numeric.columns, index=df_missing_numeric.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separació de les variables categòriques\n",
    "categorical_cols = df_missing.select_dtypes(include=['object']).columns\n",
    "df_missing_categorical = df_missing[categorical_cols]\n",
    "df_missing_categorical = df_missing_categorical.replace('NaNN', np.nan)\n",
    "\n",
    "# Funció per imputar valors categòrics\n",
    "def impute_categorical(data, cols, method='most_frequent'):\n",
    "    imputed_data = data.copy()\n",
    "    for col in cols:\n",
    "        imputer = SimpleImputer(strategy=method)\n",
    "        imputed_data[col] = imputer.fit_transform(\n",
    "            data[[col]]).ravel()  # Convertir en array 1D\n",
    "    return imputed_data\n",
    "\n",
    "# Funció per a Hot-Deck Imputation\n",
    "def hot_deck_imputation(data, cols):\n",
    "    imputed_data = data.copy()\n",
    "    for col in cols:\n",
    "        missing = imputed_data[col].isna()\n",
    "        if missing.any():\n",
    "            complete_mask = ~missing\n",
    "            missing_mask = missing\n",
    "            imputed_data.loc[missing_mask, col] = imputed_data.loc[complete_mask, col].sample(\n",
    "                n=missing.sum(), replace=True).values\n",
    "    return imputed_data\n",
    "\n",
    "\n",
    "# Imputació amb Moda\n",
    "df_categorical_mode = impute_categorical(\n",
    "    df_missing_categorical, categorical_cols, method='most_frequent')\n",
    "\n",
    "# Imputació amb Hot-Deck\n",
    "df_categorical_hot_deck = hot_deck_imputation(\n",
    "    df_missing_categorical, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_mse(original_data, imputed_data, cols):\n",
    "    mse_scores = {}\n",
    "    for col in cols:\n",
    "        # Comparar només les files on original_data no té NaNs\n",
    "        mask = original_data[col].notna()\n",
    "        mse_scores[col] = mean_squared_error(original_data.loc[mask, col], imputed_data.loc[mask, col])\n",
    "    return mse_scores\n",
    "\n",
    "\n",
    "def calculate_accuracy(original_data, imputed_data, cols):\n",
    "    accuracy_scores = {}\n",
    "    for col in cols:\n",
    "        # Reindexa imputed_data per coincidir amb original_data\n",
    "        imputed_col = imputed_data[col].reindex(original_data.index)\n",
    "        # Només compara on original_data no té NaN\n",
    "        mask = original_data[col].notna()\n",
    "        correct = original_data.loc[mask, col] == imputed_col.loc[mask]\n",
    "        # Utilitza mean() per calcular la precisió\n",
    "        accuracy_scores[col] = correct.mean()\n",
    "    return accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provem quins metodes per imputar son els millors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputem els missings amb els millors metodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa les dades numèriques i categòriques per X_train\n",
    "numeric_cols_train = train.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols_train = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Separa les dades numèriques i categòriques per X_test\n",
    "numeric_cols_test = train.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols_test = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "df_numeric_train = train[numeric_cols_train]\n",
    "df_categorical_train = train[categorical_cols_train].replace('NaNN', np.nan)\n",
    "\n",
    "df_numeric_test = train[numeric_cols_test]\n",
    "df_categorical_test = train[categorical_cols_test].replace('NaNN', np.nan)\n",
    "\n",
    "# Utilitza la funció impute_numeric que has definit abans per X_train\n",
    "df_numeric_train_imputed = impute_numeric(df_numeric_train, numeric_cols_train, model_type='random_forest')\n",
    "\n",
    "# Utilitza la mateixa funció impute_numeric per X_test\n",
    "df_numeric_test_imputed = impute_numeric(df_numeric_test, numeric_cols_test, model_type='random_forest')\n",
    "\n",
    "# Utilitza la funció hot_deck_imputation que has definit abans per X_train\n",
    "df_categorical_train_imputed = hot_deck_imputation(df_categorical_train, categorical_cols_train)\n",
    "\n",
    "# Utilitza la mateixa funció hot_deck_imputation per X_test\n",
    "df_categorical_test_imputed = hot_deck_imputation(df_categorical_test, categorical_cols_test)\n",
    "\n",
    "# Uneix les dades numèriques i categòriques imputades per X_train\n",
    "X_train_imputed = pd.concat([df_numeric_train_imputed, df_categorical_train_imputed], axis=1)\n",
    "\n",
    "# Uneix les dades numèriques i categòriques imputades per X_test\n",
    "X_test_imputed = pd.concat([df_numeric_test_imputed, df_categorical_test_imputed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula els missings per a cada columna abans del preprocessament\n",
    "missings_before_train = train.isna().sum()\n",
    "missings_before_test = train.isna().sum()\n",
    "\n",
    "# Calcula els missings per a cada columna després del preprocessament\n",
    "missings_after_train = X_train_imputed.isna().sum()\n",
    "missings_after_test = X_test_imputed.isna().sum()\n",
    "\n",
    "# Imprimeix els resultats\n",
    "print(\"Missings abans del preprocessament en X_train:\")\n",
    "print(missings_before_train)\n",
    "print(\"\\nMissings després del preprocessament en X_train:\")\n",
    "print(missings_after_train)\n",
    "\n",
    "print(\"\\nMissings abans del preprocessament en X_test:\")\n",
    "print(missings_before_test)\n",
    "print(\"\\nMissings després del preprocessament en X_test:\")\n",
    "print(missings_after_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tornem a convertir a numeriques les variables que tractarem com a tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELITZACIÓ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model lineal base\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar i avaluar\n",
    "Entrenar i avaluar un model de regressió lineal o regressió logística segons la natura del problema (regressió o classificació). Entrenarem un model de regressió lineal per predir el preu dels dispositius mòbils, per tant el problema és de regressió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretar els resultats obtinguts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procés iteratiu (MLP)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model guanyador i conclusions\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
